{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Notebook Overview**\n\nThis notebook implements a reproducible pipeline for **parameter-efficient personalization of Stable Diffusion v1.5** using **LoRA**. It provides end-to-end scripts for training, evaluation, and controlled style mixing, designed to run on a single GPU with careful memory management.\n\n* **Core setup**: Loads VAE/UNet/CLIP from `runwayml/stable-diffusion-v1-5`, applies LoRA adapters to cross-attention projections in both UNet and text encoder, and selects precision dynamically (`bf16` if available, else `fp16`; override via `LORA_SCRIPT_DTYPE`). TF32 is enabled when possible.\n* **Data interface**: Assumes per-style image folders under `MAIN/Datasets/<style>/` with optional one-line `.txt` captions. If captions are absent or mismatched, the loader falls back to a default style caption. A small **validation prompt** file is auto-materialized at `Datasets/prompts/validation_prompt.txt`.\n* **Training loop**: Uses DDPMScheduler noise, SNR-weighted MSE loss (`γ=5`) to reweight timesteps, cosine-with-restarts LR schedule with warmup, gradient checkpointing, and attention/tiling optimizations. Runs are organized under `MAIN/runs/<Exp-*>/...` with timestamped directories and a `latest` symlink.\n* **Evaluation**: For each run, the notebook generates images for the validation prompts and computes available metrics:\n\n  * CLIP score (CPU) out of the box.\n  * Optional **FID** (cleanfid), **IS/KID** (torch-fidelity), and **LPIPS diversity** (lpips) if libraries are installed; otherwise they are skipped gracefully.\n  * A no-finetune **baseline** can be generated for direct Δ comparisons.\n    Metrics and configs are persisted as JSON; aggregate CSVs are appended per experiment. A thumbnail strip is saved for quick visual inspection.\n* **Experiments (ready-to-run)**:\n\n  * `run_exp1_multi(...)`: multi-style LoRA benchmark (e.g., `ghibli`, `shinkai`, `comic`) with shared hyperparameters.\n  * `run_exp2_ablation(...)`: grid search over rank/steps/lr for a target style.\n  * `run_exp3_compare(...)`: side-by-side **LoRA vs. Textual Inversion vs. DreamBooth** with consistent prompts and metrics.\n  * `run_exp4_style_mixing(...)`: **linear interpolation** of two merged LoRA checkpoints (UNet + text encoder) to produce smooth hybrid styles for a given prompt.\n* **Reproducibility & housekeeping**: Global seeding, bounded dataloader workers, periodic logging to file, automatic checkpoint/dir sizing, GPU memory cleanup, and pruning of older timestamped runs (`keep_last=3`).\n\n**Default knobs**: `steps=1000`, `rank=32`, `lr=1e-4`, `GEN_STEPS=30`, `GUIDANCE=7.5`, `RESOLUTION=512`. Paths can be customized via `LORA_ROOT`, `LORA_MAIN`, `LORA_PROJECT`, `LORA_DATASETS`. The pipeline prints device/precision at start and records VRAM peaks when CUDA is available.","metadata":{}},{"cell_type":"markdown","source":"### 0.1. Before Experiment Dependency Installation\n#### This block installs all required Python packages using pip. Specific versions are pinned (e.g., diffusers==0.29.1) to ensure the code is reproducible. It includes the core Hugging Face ecosystem (transformers, diffusers, peft) for diffusion models and fine-tuning, along with libraries for performance evaluation (torch-fidelity, clean-fid).\n\n","metadata":{}},{"cell_type":"code","source":"!pip install timm==1.0.7\n!pip install fairscale==0.4.13\n!pip install transformers==4.41.2\n!pip install requests==2.31.0\n!pip install accelerate==0.31.0\n!pip install diffusers==0.29.1\n!pip install einop==0.0.1\n!pip install safetensors==0.4.3\n!pip install voluptuous==0.15.1\n!pip install peft==0.11.1\n!pip install deepface==0.0.90\n!pip install tensorflow==2.9.0\n!pip install keras==2.9.0\n!pip install torch-fidelity lpips\n!pip install clean-fid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:38:48.215508Z","iopub.execute_input":"2025-09-29T19:38:48.215849Z","iopub.status.idle":"2025-09-29T19:42:20.851539Z","shell.execute_reply.started":"2025-09-29T19:38:48.215825Z","shell.execute_reply":"2025-09-29T19:42:20.850149Z"}},"outputs":[{"name":"stdout","text":"Collecting timm==1.0.7\n  Downloading timm-1.0.7-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==1.0.7) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==1.0.7) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==1.0.7) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==1.0.7) (0.33.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==1.0.7) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.7) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm==1.0.7)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm==1.0.7)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm==1.0.7)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm==1.0.7)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm==1.0.7)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm==1.0.7)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->timm==1.0.7)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm==1.0.7)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm==1.0.7)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm==1.0.7)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.7) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm==1.0.7) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==1.0.7) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm==1.0.7) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm==1.0.7) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm==1.0.7) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.7) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.7) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.7) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.7) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm==1.0.7) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm==1.0.7) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm==1.0.7) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm==1.0.7) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm==1.0.7) (2024.2.0)\nDownloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.15\n    Uninstalling timm-1.0.15:\n      Successfully uninstalled timm-1.0.15\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 timm-1.0.7\nCollecting fairscale==0.4.13\n  Downloading fairscale-0.4.13.tar.gz (266 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fairscale==0.4.13) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from fairscale==0.4.13) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->fairscale==0.4.13) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->fairscale==0.4.13) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->fairscale==0.4.13) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->fairscale==0.4.13) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->fairscale==0.4.13) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.0->fairscale==0.4.13) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.0->fairscale==0.4.13) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.0->fairscale==0.4.13) (2024.2.0)\nBuilding wheels for collected packages: fairscale\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=15355d908cda1744d1bebf2286928682784a329e104f34a88acdb98d415f58c4\n  Stored in directory: /root/.cache/pip/wheels/95/ef/96/5044bde220b2ea299bdc6ec05051e0ef187fad45b341d1c273\nSuccessfully built fairscale\nInstalling collected packages: fairscale\nSuccessfully installed fairscale-0.4.13\nCollecting transformers==4.41.2\n  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.4)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.41.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.41.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\nSuccessfully installed tokenizers-0.19.1 transformers-4.41.2\nCollecting requests==2.31.0\n  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2025.6.15)\nDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: requests\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.4\n    Uninstalling requests-2.32.4:\n      Successfully uninstalled requests-2.32.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ndatasets 3.6.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed requests-2.31.0\nCollecting accelerate==0.31.0\n  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (0.33.1)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (0.5.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->accelerate==0.31.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.31.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.31.0) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.31.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.31.0) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.31.0) (1.1.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.31.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->accelerate==0.31.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->accelerate==0.31.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->accelerate==0.31.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->accelerate==0.31.0) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.31.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.31.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.31.0) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->accelerate==0.31.0) (2024.2.0)\nDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.8.1\n    Uninstalling accelerate-1.8.1:\n      Successfully uninstalled accelerate-1.8.1\nSuccessfully installed accelerate-0.31.0\nCollecting diffusers==0.29.1\n  Downloading diffusers-0.29.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (8.7.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (3.18.0)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (0.33.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (0.5.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.1) (11.2.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (6.0.2)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.1) (1.1.5)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.29.1) (3.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->diffusers==0.29.1) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.1) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers==0.29.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->diffusers==0.29.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->diffusers==0.29.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->diffusers==0.29.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->diffusers==0.29.1) (2024.2.0)\nDownloading diffusers-0.29.1-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\n  Attempting uninstall: diffusers\n    Found existing installation: diffusers 0.34.0\n    Uninstalling diffusers-0.34.0:\n      Successfully uninstalled diffusers-0.34.0\nSuccessfully installed diffusers-0.29.1\nCollecting einop==0.0.1\n  Downloading einop-0.0.1-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: einops>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from einop==0.0.1) (0.8.1)\nDownloading einop-0.0.1-py3-none-any.whl (3.0 kB)\nInstalling collected packages: einop\nSuccessfully installed einop-0.0.1\nCollecting safetensors==0.4.3\n  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: safetensors\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.5.3\n    Uninstalling safetensors-0.5.3:\n      Successfully uninstalled safetensors-0.5.3\nSuccessfully installed safetensors-0.4.3\nCollecting voluptuous==0.15.1\n  Downloading voluptuous-0.15.1.tar.gz (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: voluptuous\n  Building wheel for voluptuous (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for voluptuous: filename=voluptuous-0.15.1-py3-none-any.whl size=31435 sha256=257bcf63b4d07a85ebce73aa4d862948577f92c3e4d3eacfc2a283bc01128365\n  Stored in directory: /root/.cache/pip/wheels/19/38/78/11274b56d7ecd36ebe26c8700be7fa15d85c0a93f067616b0f\nSuccessfully built voluptuous\nInstalling collected packages: voluptuous\nSuccessfully installed voluptuous-0.15.1\nCollecting peft==0.11.1\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.41.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.31.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (0.33.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2025.5.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.17.0->peft==0.11.1) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.11.1) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.11.1) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (2024.11.6)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.11.1) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.11.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.11.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft==0.11.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft==0.11.1) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.11.1) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft==0.11.1) (2024.2.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.15.2\n    Uninstalling peft-0.15.2:\n      Successfully uninstalled peft-0.15.2\nSuccessfully installed peft-0.11.1\nCollecting deepface==0.0.90\n  Downloading deepface-0.0.90-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (2.31.0)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (1.26.4)\nRequirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (2.2.3)\nRequirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (5.2.0)\nRequirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (4.67.1)\nRequirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (11.2.1)\nRequirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (4.11.0.86)\nRequirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (2.18.0)\nRequirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (3.8.0)\nRequirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface==0.0.90) (3.1.1)\nCollecting mtcnn>=0.1.0 (from deepface==0.0.90)\n  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting retina-face>=0.0.1 (from deepface==0.0.90)\n  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\nCollecting fire>=0.4.0 (from deepface==0.0.90)\n  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting gunicorn>=20.1.0 (from deepface==0.0.90)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface==0.0.90) (3.1.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (1.9.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (8.2.1)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface==0.0.90) (3.1.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface==0.0.90) (4.13.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface==0.0.90) (3.18.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface==0.0.90) (25.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (1.4.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.1.0)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (3.14.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.16.0)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface==0.0.90) (0.4.1)\nRequirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface==0.0.90) (1.5.1)\nCollecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface==0.0.90)\n  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->deepface==0.0.90) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface==0.0.90) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface==0.0.90) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface==0.0.90) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface==0.0.90) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface==0.0.90) (2025.6.15)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (3.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (3.20.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.17.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (4.14.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (1.73.1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (2.18.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface==0.0.90) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface==0.0.90) (0.45.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface==0.0.90) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface==0.0.90) (0.7.2)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface==0.0.90) (2.7)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->deepface==0.0.90) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->deepface==0.0.90) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->deepface==0.0.90) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->deepface==0.0.90) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface==0.0.90) (1.7.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface==0.0.90) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface==0.0.90) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->deepface==0.0.90) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface==0.0.90) (0.1.2)\nDownloading deepface-0.0.90-py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\nDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lz4, gunicorn, fire, mtcnn, retina-face, deepface\nSuccessfully installed deepface-0.0.90 fire-0.7.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\n\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.9.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.9.0\u001b[0m\u001b[31m\n\u001b[0mCollecting keras==2.9.0\n  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.8.0\n    Uninstalling keras-3.8.0:\n      Successfully uninstalled keras-3.8.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.18.0 requires keras>=3.5.0, but you have keras 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.9.0\nCollecting torch-fidelity\n  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\nCollecting lpips\n  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (11.2.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.15.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (0.21.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\nDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\nDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-fidelity, lpips\nSuccessfully installed lpips-0.1.4 torch-fidelity-0.3.0\nCollecting clean-fid\n  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clean-fid) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clean-fid) (0.21.0+cu124)\nRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from clean-fid) (1.26.4)\nRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid) (1.15.3)\nRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid) (4.67.1)\nRequirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.11/dist-packages (from clean-fid) (11.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from clean-fid) (2.31.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->clean-fid) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->clean-fid) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clean-fid) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clean-fid) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clean-fid) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->clean-fid) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->clean-fid) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.3->clean-fid) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.3->clean-fid) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.3->clean-fid) (2024.2.0)\nDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\nInstalling collected packages: clean-fid\nSuccessfully installed clean-fid-0.1.35\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 0.2. Before Experiment Workspace and Dataset Setup\n#### This block configures the project workspace. It defines a directory structure for datasets, logs, and image outputs, then creates these folders. It also automates the data preparation by downloading a sample dataset from Google Drive with gdown and unzipping it into the correct location, making the notebook ready to run.","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport glob\nimport json\nimport time\nimport subprocess\nfrom pathlib import Path\n\n# ========== Path Settings ==========\n# Define the names for the current project and the dataset to be used.\nproject_name = \"ghibli\"\ndataset_name = \"ghibli\"\n\n# Construct the main directory structure.\nroot_dir = \"./\"\nmain_dir = os.path.join(root_dir, \"SD\")\nproject_dir = os.path.join(main_dir, project_name)\n\n# Define specific paths for images, captions, outputs, and prompts.\nimages_folder = os.path.join(main_dir, \"Datasets\", dataset_name)\nprompts_folder = os.path.join(main_dir, \"Datasets\", \"prompts\")\ncaptions_folder = images_folder\noutput_folder = os.path.join(project_dir, \"logs\")\n\n# Define the path for the validation prompt file.\nvalidation_prompt_name = \"validation_prompt.txt\"\nvalidation_prompt_path = os.path.join(prompts_folder, validation_prompt_name)\n\n# Define paths for model checkpoints, the dataset zip, and inference output.\nmodel_path = os.path.join(project_dir, \"logs\", \"checkpoint-last\")\nzip_file = os.path.join(main_dir, \"Datasets.zip\")\ninference_path = os.path.join(project_dir, \"inference\")\n\n# Create all the defined directories if they don't already exist.\nos.makedirs(images_folder, exist_ok=True)\nos.makedirs(prompts_folder, exist_ok=True)\nos.makedirs(output_folder, exist_ok=True)\nos.makedirs(inference_path, exist_ok=True)\n\n# Download and unzip the sample dataset (requires 'gdown' to be executable).\nprint(\"📂 Downloading and extracting the sample dataset...\")\ntry:\n    # Use gdown to download the file from Google Drive.\n    subprocess.run([\"gdown\", \"1GjHgyBJYhYhCeNVmqyVobevd4DeGYAdD\", \"-O\", zip_file], check=False)\n    if os.path.exists(zip_file):\n        # Unzip the file quietly (-q) and overwrite existing files (-o).\n        subprocess.run([\"unzip\", \"-q\", \"-o\", zip_file, \"-d\", main_dir], check=True)\n        print(f\"Project {project_name} is ready!\")\n    else:\n        print(\" ataset zip file 'Datasets.zip' not found!\")\nexcept Exception as e:\n    print(f\"An error occurred during the unzip process: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:20.854252Z","iopub.execute_input":"2025-09-29T19:42:20.854612Z","iopub.status.idle":"2025-09-29T19:42:25.449773Z","shell.execute_reply.started":"2025-09-29T19:42:20.854569Z","shell.execute_reply":"2025-09-29T19:42:25.448621Z"}},"outputs":[{"name":"stdout","text":"📂 Downloading and extracting the sample dataset...\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=17elrLMzJMkuMGoSU8d6B7D_4QOq5U2n1\nFrom (redirected): https://drive.google.com/uc?id=17elrLMzJMkuMGoSU8d6B7D_4QOq5U2n1&confirm=t&uuid=46ae7d20-b1b3-4aab-858c-927232fb557d\nTo: /kaggle/working/SD/Datasets.zip\n100%|██████████| 91.5M/91.5M [00:01<00:00, 77.8MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Project ghibli is ready!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 1. Imports and Environment Setup\n#### This first block handles all necessary imports, from standard Python libraries to specialized ones like torch, diffusers, and peft. It also attempts to import optional libraries for performance metrics (FID, LPIPS) and sets up the global device (cuda or cpu) and data type (bfloat16 or float16) for the experiments.","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport os, re, gc, math, glob, json, time, csv, random\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Optional, List, Tuple\n\nimport torch, torch.nn.functional as F\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\n\nfrom transformers import CLIPTextModel, CLIPTokenizer, CLIPModel, CLIPProcessor\nfrom diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel, DiffusionPipeline\nfrom diffusers.optimization import get_scheduler\nfrom diffusers.training_utils import compute_snr\nfrom peft import LoraConfig, get_peft_model, PeftModel\n\n# ---------- Optional metrics ----------\n# Check for the availability of optional metric calculation libraries.\n# These flags will be used later to conditionally run evaluation steps.\nHAS_FID = False\ntry:\n    from cleanfid import fid as clean_fid\n    HAS_FID = True\nexcept Exception:\n    HAS_FID = False\n\nHAS_TFID = False\ntry:\n    import torch_fidelity\n    HAS_TFID = True\nexcept Exception:\n    HAS_TFID = False\n\nHAS_LPIPS = False\ntry:\n    import lpips as lpips_lib\n    HAS_LPIPS = True\nexcept Exception:\n    HAS_LPIPS = False\n\n# ---------- Device and Dtype Configuration ----------\n# Set the primary device to CUDA if available, otherwise fallback to CPU.\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Determine the floating-point precision (dtype) for training.\n# Prefers BF16 on supported hardware, otherwise FP16. Can be overridden by environment variable.\n_env_dtype = os.environ.get(\"LORA_SCRIPT_DTYPE\", \"\")\nif _env_dtype.lower() == \"fp16\":\n    DTYPE = torch.float16\nelif _env_dtype.lower() == \"bf16\":\n    DTYPE = torch.bfloat16\nelse:\n    DTYPE = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else torch.float16\nprint(f\"[device] {DEVICE} | dtype={DTYPE}\")\n\n# Enable TF32 for faster matrix multiplications on Ampere+ GPUs if available.\ntry:\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\nexcept Exception:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:25.450857Z","iopub.execute_input":"2025-09-29T19:42:25.451115Z","iopub.status.idle":"2025-09-29T19:42:54.261540Z","shell.execute_reply.started":"2025-09-29T19:42:25.451096Z","shell.execute_reply":"2025-09-29T19:42:54.260234Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n2025-09-29 19:42:38.616793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759174958.865088      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759174958.939348      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[device] cpu | dtype=torch.float16\n","output_type":"stream"},{"name":"stderr","text":"No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 2. Global Configuration and Constants\n#### This block defines all the hyperparameters, paths, and constants that will be used throughout the experiments. Centralizing these makes it easy to adjust settings for different runs without digging through the code.","metadata":{}},{"cell_type":"code","source":"# ---------- Training & Inference Hyperparameters ----------\nDEFAULT_STEPS = 1000\nDEFAULT_RANK = 32\nDEFAULT_LR = 1e-4\nGEN_STEPS = 30\nGUIDANCE = 7.5\nBATCH_SIZE = 2\nTI_DB_BATCH = 1\nRESOLUTION = 512\nSNR_GAMMA = 5\nSEED = 1126\n\n# ---------- Learning Rate Scheduler Settings ----------\nLR_SCHEDULER = \"cosine_with_restarts\"\nLR_WARMUP = 100\nNUM_CYCLES = 3\n\n# ---------- Model and Path Configuration ----------\nPRETRAINED = \"runwayml/stable-diffusion-v1-5\"\n\n# Define root directories for the project, datasets, and experiment runs.\n# These can be configured via environment variables.\nROOT = Path(os.environ.get(\"LORA_ROOT\", \"./\"))\nMAIN = Path(os.environ.get(\"LORA_MAIN\", str(ROOT / \"SD\")))\nPROJECT = Path(os.environ.get(\"LORA_PROJECT\", str(MAIN / \"ghibli\")))\nDATASETS = Path(os.environ.get(\"LORA_DATASETS\", str(MAIN / \"Datasets\")))\nPROMPTS_DIR = DATASETS / \"prompts\"\nPROMPTS_FILE = PROMPTS_DIR / \"validation_prompt.txt\"\nRUNS_ROOT = MAIN / \"runs\"\n\n# Cap the number of data loader workers to avoid system overload.\ndef _cap_workers(n: int) -> int:\n    try:\n        cpu = os.cpu_count() or 2\n    except Exception:\n        cpu = 2\n    return max(0, min(n, 2, cpu))\nNUM_WORKERS = _cap_workers(int(os.environ.get(\"LORA_NUM_WORKERS\", \"2\")))\n\n# Create project and prompt directories if they don't exist.\nPROJECT.mkdir(parents=True, exist_ok=True)\nPROMPTS_DIR.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.263769Z","iopub.execute_input":"2025-09-29T19:42:54.264430Z","iopub.status.idle":"2025-09-29T19:42:54.276147Z","shell.execute_reply.started":"2025-09-29T19:42:54.264400Z","shell.execute_reply":"2025-09-29T19:42:54.274760Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 3. Utility Functions\n#### Here are various helper functions for tasks like formatting file names, managing directories, handling files (JSON, images), setting random seeds, and managing GPU memory. The RunPaths class is a key utility for organizing the outputs of each experiment run into a structured directory hierarchy.","metadata":{}},{"cell_type":"code","source":"def _fmt_float(f: float) -> str:\n    \"\"\"Formats a float in scientific notation for filenames.\"\"\"\n    return f\"{f:.1e}\"\n\ndef make_cfg_tag(method: str, style: str, r: Optional[int]=None, steps: Optional[int]=None,\n                 lr_unet: Optional[float]=None, lr_text: Optional[float]=None) -> str:\n    \"\"\"Creates a standardized configuration tag for naming experiment directories.\"\"\"\n    parts = []\n    if r is not None: parts.append(f\"r{r}\")\n    if steps is not None: parts.append(f\"s{steps}\")\n    if lr_unet is not None: parts.append(f\"lru{_fmt_float(lr_unet)}\")\n    if lr_text is not None: parts.append(f\"lrt{_fmt_float(lr_text)}\")\n    return \"_\".join(parts) if parts else \"default\"\n\ndef now_run_id() -> str:\n    \"\"\"Generates a timestamp-based unique ID for a run.\"\"\"\n    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\ndef ensure_dir(p: Path):\n    \"\"\"Ensures a directory exists, creating it if necessary.\"\"\"\n    p.mkdir(parents=True, exist_ok=True); return p\n\ndef write_json(p: Path, obj: Dict):\n    \"\"\"Writes a dictionary to a JSON file.\"\"\"\n    p.parent.mkdir(parents=True, exist_ok=True)\n    p.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n\ndef safe_symlink(target: Path, link_path: Path):\n    \"\"\"Creates a symlink, safely removing any existing file or link at the destination.\"\"\"\n    try:\n        if link_path.exists() or link_path.is_symlink(): link_path.unlink()\n        link_path.symlink_to(target.name)\n    except Exception:\n        pass\n\ndef stitch_strip(img_paths, save_path: Path, max_w: Optional[int]=None, max_h: Optional[int]=None):\n    \"\"\"Stitches a list of images horizontally into a single image strip.\"\"\"\n    if not img_paths: return None\n    ims = [Image.open(p).convert(\"RGB\") for p in img_paths]\n    # Optional resizing\n    if max_w or max_h:\n        _w, _h = ims[0].size\n        if max_w and _w > max_w:\n            ratio = max_w / _w; _w = max_w; _h = int(_h * ratio)\n            ims = [im.resize((_w,_h), Image.BICUBIC) for im in ims]\n        if max_h and ims[0].size[1] > max_h:\n            _w,_h = ims[0].size\n            ratio = max_h / _h; _h = max_h; _w = int(_w * ratio)\n            ims = [im.resize((_w,_h), Image.BICUBIC) for im in ims]\n    w,h = ims[0].size\n    canvas = Image.new(\"RGB\", (w*len(ims), h))\n    for i,im in enumerate(ims):\n        if im.size != (w,h): im = im.resize((w,h), Image.BICUBIC)\n        canvas.paste(im, (i*w,0))\n    ensure_dir(save_path.parent); canvas.save(save_path); return str(save_path)\n\nclass RunPaths:\n    \"\"\"A helper class to manage all file paths for a single experiment run.\"\"\"\n    def __init__(self, exp: str, method: str, style: str, cfg_tag: str, with_compare: bool=False):\n        self.exp, self.method, self.style, self.cfg, self.with_compare = exp, method, style, cfg_tag, with_compare\n        self.run_id = now_run_id()\n        # Structure paths differently for Exp-III to group comparisons\n        if exp == \"Exp-III\":\n            self.base = RUNS_ROOT / exp / \"compare\" / style / cfg_tag / self.run_id / method\n        else:\n            self.base = RUNS_ROOT / exp / method / style / cfg_tag / self.run_id\n        self.ckpt = self.base / \"checkpoints\"\n        self.infer = self.base / \"inference\"\n        self.thumb = self.infer / \"thumbnails\"\n        self.logs = self.base / \"logs.txt\"\n        self.metrics = self.base / \"metrics.json\"\n        self.cfg_json = self.base / \"config.json\"\n        self.latest_link = self.base.parent / \"latest\"\n\n    def materialize(self):\n        \"\"\"Creates all necessary directories for the run.\"\"\"\n        ensure_dir(self.ckpt); ensure_dir(self.infer); ensure_dir(self.thumb); ensure_dir(self.base); return self\n\n    def finalize_latest(self):\n        \"\"\"Creates a 'latest' symlink pointing to the current run's directory.\"\"\"\n        safe_symlink(Path(self.run_id), self.latest_link)\n\ndef cleanup_runs(cfg_root: Path, keep_last: int = 3):\n    \"\"\"Deletes old run directories to save space, keeping the most recent ones.\"\"\"\n    if not cfg_root.exists(): return\n    items = [p for p in cfg_root.iterdir() if p.is_dir() and re.match(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\", p.name)]\n    items = sorted(items, key=lambda p: p.name, reverse=True)\n    for p in items[keep_last:]:\n        try:\n            # Delete files first, then directories\n            for sub in p.rglob(\"*\"):\n                if sub.is_file(): sub.unlink()\n            for sub in sorted(p.rglob(\"*\"), reverse=True):\n                if sub.is_dir(): sub.rmdir()\n            p.rmdir()\n        except Exception:\n            pass\n\ndef free_cuda_memory(*objs):\n    \"\"\"Frees up GPU memory by deleting objects and clearing the cache.\"\"\"\n    for o in objs:\n        try:\n            if hasattr(o, \"to\"): o.to(\"cpu\")\n        except Exception:\n            pass\n    for o in objs:\n        try: del o\n        except Exception: pass\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n\ndef set_seed(seed=SEED):\n    \"\"\"Sets the random seed for reproducibility across libraries.\"\"\"\n    torch.manual_seed(seed); random.seed(seed)\n    try:\n        import numpy as np; np.random.seed(seed)\n    except Exception:\n        pass\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef set_sdp_math_only():\n    \"\"\"Configures Scaled Dot Product Attention to use the math backend, avoiding others that might have issues.\"\"\"\n    try:\n        torch.backends.cuda.enable_flash_sdp(False)\n        torch.backends.cuda.enable_mem_efficient_sdp(False)\n        torch.backends.cuda.enable_math_sdp(True)\n        print(\"[sdp] flash=False, mem_efficient=False, math=True\")\n    except Exception:\n        pass\n\ndef enable_safe_gradient_checkpointing(unet, text_encoder):\n    \"\"\"Enables gradient checkpointing with a safer 'use_reentrant=False' argument to save memory.\"\"\"\n    set_sdp_math_only()\n    try: unet.enable_gradient_checkpointing(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n    except TypeError: unet.enable_gradient_checkpointing()\n    try: text_encoder.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n    except TypeError: text_encoder.gradient_checkpointing_enable()\n\ndef ensure_prompts_file(path: Path):\n    \"\"\"Creates a default validation prompts file if one doesn't exist.\"\"\"\n    if not path.exists():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        path.write_text(\"\\n\".join([\n            \"a portrait of a girl, ghibli style\",\n            \"a cottage in the forest, ghibli style\",\n            \"a cat riding a train, whimsical, ghibli style\",\n        ]), encoding=\"utf-8\")\n        print(f\"[prompts] default prompts written to: {path}\")\n\ndef load_prompts(path: Path):\n    \"\"\"Loads validation prompts from a text file.\"\"\"\n    ensure_prompts_file(path)\n    lines = [ln.strip() for ln in path.read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n    return lines or [\"a whimsical scene, ghibli style\"] # Fallback prompt\n\ndef dir_size_mb(p: Path):\n    \"\"\"Calculates the total size of a directory in megabytes.\"\"\"\n    total = 0\n    for root, _, files in os.walk(p):\n        for fn in files: total += os.path.getsize(os.path.join(root, fn))\n    return total / (1024 * 1024)\n\ndef logw(log_fp: Path, msg: str):\n    \"\"\"Writes a timestamped message to a log file.\"\"\"\n    log_fp.parent.mkdir(parents=True, exist_ok=True)\n    with open(log_fp, \"a\", encoding=\"utf-8\") as f:\n        ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        f.write(f\"[{ts}] {msg}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.277347Z","iopub.execute_input":"2025-09-29T19:42:54.277628Z","iopub.status.idle":"2025-09-29T19:42:54.339860Z","shell.execute_reply.started":"2025-09-29T19:42:54.277606Z","shell.execute_reply":"2025-09-29T19:42:54.338967Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### 4. Dataset and Data Loading\n#### This section defines the custom torch.utils.data.Dataset for loading image-caption pairs. It's designed to be flexible, handling cases where captions are provided in .txt files or falling back to a default caption if they are missing.","metadata":{}},{"cell_type":"code","source":"# A list of common image file extensions to search for.\nIMAGE_EXTS = [\".png\",\".jpg\",\".jpeg\",\".webp\",\".bmp\",\".PNG\",\".JPG\",\".JPEG\",\".WEBP\",\".BMP\"]\n\nclass Text2ImageDataset(torch.utils.data.Dataset):\n    \"\"\"\n    A custom PyTorch Dataset to load images and their corresponding text captions.\n    It automatically pairs images with .txt files of the same name.\n    If no matching .txt file is found, a default caption is used.\n    \"\"\"\n    def __init__(self, images_folder, captions_folder, transform, tokenizer, default_caption: str=None):\n        # Find all images with supported extensions.\n        self.image_paths = []\n        for ext in IMAGE_EXTS:\n            self.image_paths.extend(glob.glob(str(Path(images_folder) / f\"*{ext}\")))\n        self.image_paths = sorted(self.image_paths)\n        if len(self.image_paths) == 0:\n            raise ValueError(f\"No images found in {images_folder}\")\n        \n        # Find all .txt caption files.\n        caption_paths = sorted(glob.glob(str(Path(captions_folder) / \"*.txt\")))\n        captions = []\n        \n        # If no caption files exist, use a default caption for all images.\n        if len(caption_paths) == 0:\n            default_caption = default_caption or \"an illustration in Ghibli style\"\n            captions = [default_caption] * len(self.image_paths)\n        else:\n            # Create a mapping from filename stem to file path for both images and texts.\n            img_map = {Path(p).stem: p for p in self.image_paths}\n            txt_map = {Path(p).stem: p for p in caption_paths}\n            common = sorted(set(img_map) & set(txt_map))\n            \n            # If no images and texts have matching names, use default caption.\n            if len(common) == 0:\n                default_caption = default_caption or \"an illustration in Ghibli style\"\n                captions = [default_caption] * len(self.image_paths)\n            else:\n                # Filter to only use images that have a corresponding caption.\n                self.image_paths = [img_map[k] for k in common]\n                for k in common:\n                    with open(txt_map[k], \"r\", encoding=\"utf-8\") as f:\n                        line = (f.readline() or \"\").strip()\n                        captions.append(line if line else \"an illustration\")\n                # If all captions are empty, revert to the default.\n                if all(len(c.strip()) == 0 for c in captions):\n                    default_caption = default_caption or \"an illustration in Ghibli style\"\n                    captions = [default_caption] * len(self.image_paths)\n        \n        # Tokenize all captions.\n        inputs = tokenizer(captions, max_length=tokenizer.model_max_length,\n                           padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n        if \"input_ids\" not in inputs or inputs[\"input_ids\"].nelement() == 0:\n            raise ValueError(\"Tokenizer produced empty input_ids.\")\n        \n        self.input_ids = inputs[\"input_ids\"]\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        input_id = self.input_ids[idx]\n        try:\n            # Open, convert to RGB, and apply transformations.\n            image = Image.open(img_path).convert(\"RGB\")\n            tensor = self.transform(image)\n        except Exception:\n            # Return a zero tensor if image loading fails.\n            tensor = torch.zeros((3, RESOLUTION, RESOLUTION))\n            input_id = torch.zeros_like(input_id)\n        return tensor, input_id\n\n    def __len__(self):\n        return len(self.image_paths)\n\ndef collate_fn(examples):\n    \"\"\"Custom collate function to stack image tensors and input_ids into batches.\"\"\"\n    pixel_values = torch.stack([e[0] for e in examples], dim=0).float()\n    input_ids = torch.stack([e[1] for e in examples], dim=0)\n    return {\"pixel_values\": pixel_values, \"input_ids\": input_ids}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.341141Z","iopub.execute_input":"2025-09-29T19:42:54.341481Z","iopub.status.idle":"2025-09-29T19:42:54.369589Z","shell.execute_reply.started":"2025-09-29T19:42:54.341451Z","shell.execute_reply":"2025-09-29T19:42:54.368507Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### 5. Model and Optimizer Preparation\n#### These functions prepare the core components for training. prepare_lora_model loads the pretrained Stable Diffusion models (UNet, VAE, Text Encoder) and applies the LoRA configuration using peft. prepare_optimizer sets up the AdamW optimizer, allowing for different learning rates for the UNet and Text Encoder.","metadata":{}},{"cell_type":"code","source":"def prepare_lora_model(lora_cfg, pretrained_model_name_or_path, model_path=None, resume=False, merge_lora=False):\n    \"\"\"Loads all necessary models and applies LoRA configuration.\"\"\"\n    # Load base models from Hugging Face Hub.\n    noise_scheduler = DDPMScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n    tokenizer = CLIPTokenizer.from_pretrained(pretrained_model_name_or_path, subfolder=\"tokenizer\")\n    text_encoder = CLIPTextModel.from_pretrained(pretrained_model_name_or_path, torch_dtype=DTYPE, subfolder=\"text_encoder\")\n    vae = AutoencoderKL.from_pretrained(pretrained_model_name_or_path, subfolder=\"vae\", torch_dtype=DTYPE)\n    unet = UNet2DConditionModel.from_pretrained(pretrained_model_name_or_path, torch_dtype=DTYPE, subfolder=\"unet\")\n\n    # Enable VAE tiling for memory efficiency.\n    try: vae.enable_tiling()\n    except Exception: pass\n\n    # If resuming, load LoRA weights from a checkpoint. Otherwise, initialize new LoRA layers.\n    if resume:\n        if model_path is None or not Path(model_path).exists():\n            raise ValueError(\"resume=True requires valid model_path\")\n        text_encoder = PeftModel.from_pretrained(text_encoder, str(Path(model_path) / \"text_encoder\"))\n        unet = PeftModel.from_pretrained(unet, str(Path(model_path) / \"unet\"))\n    else:\n        text_encoder = get_peft_model(text_encoder, lora_cfg)\n        unet = get_peft_model(unet, lora_cfg)\n\n    # If merging, unload LoRA layers and merge their weights into the base model for faster inference.\n    if merge_lora:\n        text_encoder = text_encoder.merge_and_unload()\n        unet = unet.merge_and_unload()\n        text_encoder.eval(); unet.eval()\n\n    # Freeze VAE weights and move all models to the target device.\n    vae.requires_grad_(False)\n    unet.to(DEVICE, dtype=DTYPE); vae.to(DEVICE, dtype=DTYPE); text_encoder.to(DEVICE, dtype=DTYPE)\n    return tokenizer, noise_scheduler, unet, vae, text_encoder\n\ndef prepare_optimizer(unet, text_encoder, unet_lr, text_lr):\n    \"\"\"Prepares the AdamW optimizer with separate learning rates for UNet and Text Encoder.\"\"\"\n    unet_params = [p for p in unet.parameters() if p.requires_grad]\n    te_params = [p for p in text_encoder.parameters() if p.requires_grad]\n    return torch.optim.AdamW([\n        {\"params\": unet_params, \"lr\": unet_lr},\n        {\"params\": te_params, \"lr\": text_lr}\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.370704Z","iopub.execute_input":"2025-09-29T19:42:54.370973Z","iopub.status.idle":"2025-09-29T19:42:54.401560Z","shell.execute_reply.started":"2025-09-29T19:42:54.370951Z","shell.execute_reply":"2025-09-29T19:42:54.400547Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### 6. Evaluation Metrics\n#### This block contains functions for calculating various image quality and diversity metrics. It includes CLIP score (text-image alignment), FID (realism and diversity), IS/KID (quality and diversity), and LPIPS (perceptual diversity). The main evaluate_generation function orchestrates these calculations.","metadata":{}},{"cell_type":"code","source":"def _load_clip_cpu():\n    \"\"\"Loads the CLIP model and processor to the CPU.\"\"\"\n    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(\"cpu\")\n    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n    clip_model.eval(); return clip_model, clip_processor\n\n@torch.no_grad()\ndef clip_score_single(prompt: str, image_path: str, clip_model, clip_processor) -> float:\n    \"\"\"Computes the CLIP score for a single prompt-image pair.\"\"\"\n    image = Image.open(image_path).convert(\"RGB\")\n    inputs = clip_processor(text=prompt, images=image, return_tensors=\"pt\")\n    outputs = clip_model(**inputs)\n    return float(outputs.logits_per_image.item())\n\n@torch.no_grad()\ndef compute_clip_avg(prompts: List[str], image_paths: List[str]) -> float:\n    \"\"\"Computes the average CLIP score over a list of prompts and images.\"\"\"\n    clip_model, clip_processor = _load_clip_cpu()\n    score = 0.0; n = min(len(prompts), len(image_paths))\n    for i in range(n):\n        score += clip_score_single(prompts[i], image_paths[i], clip_model, clip_processor)\n    return score / max(n, 1)\n\n@torch.no_grad()\ndef compute_is_kid(gen_dir: str, ref_dir: Optional[str] = None, cuda: bool = False) -> Tuple[Optional[float], Optional[float]]:\n    \"\"\"Computes Inception Score (IS) and Kernel Inception Distance (KID) using torch-fidelity.\"\"\"\n    IS = None; KID = None\n    if not HAS_TFID: return IS, KID\n    try:\n        # Calculate IS\n        is_dict = torch_fidelity.calculate_metrics(\n            input1=gen_dir, cuda=(cuda and torch.cuda.is_available()),\n            isc=True, kid=False, fid=False, verbose=True,\n            samples_find_deep=False, batch_size=16, num_workers=0  # NOTE: num_workers=0 is crucial to avoid storage errors\n        )\n        IS = is_dict.get(\"inception_score_mean\", is_dict.get(\"isc_mean\", None))\n        if IS is not None: IS = float(IS)\n    except Exception as e:\n        print(\"[metrics] IS failed:\", e)\n\n    # Calculate KID if a reference directory is provided\n    if ref_dir is not None:\n        try:\n            kid_dict = torch_fidelity.calculate_metrics(\n                input1=gen_dir, input2=ref_dir,\n                cuda=(cuda and torch.cuda.is_available()),\n                isc=False, kid=True, fid=False, verbose=True,\n                samples_find_deep=False, batch_size=16, num_workers=0 # Also set to 0\n            )\n            KID = kid_dict.get(\"kernel_inception_distance_mean\", kid_dict.get(\"kid_mean\", None))\n            if KID is not None: KID = float(KID)\n        except Exception as e:\n            print(\"[metrics] KID failed:\", e)\n    return IS, KID\n\n@torch.no_grad()\ndef compute_fid(gen_dir: str, ref_dir: str) -> Optional[float]:\n    \"\"\"Computes Frechet Inception Distance (FID) using clean-fid.\"\"\"\n    if not HAS_FID: return None\n    try:\n        return float(clean_fid.compute_fid(gen_dir, ref_dir))\n    except Exception as e:\n        print(\"[metrics] FID failed:\", e); return None\n\n@torch.no_grad()\ndef compute_lpips_diversity(image_paths: List[str], max_pairs: int = 100) -> Optional[float]:\n    \"\"\"Computes LPIPS diversity by measuring the average distance between random pairs of generated images.\"\"\"\n    if not HAS_LPIPS or len(image_paths) < 2: return None\n    try:\n        loss_fn = lpips_lib.LPIPS(net='vgg').to(\"cpu\").eval()\n        pairs, idxs = [], list(range(len(image_paths)))\n        random.shuffle(idxs)\n        # Create random pairs of images\n        for i in range(0, min(len(idxs)-1, max_pairs*2), 2):\n            pairs.append((image_paths[idxs[i]], image_paths[idxs[i+1]]))\n            if len(pairs) >= max_pairs: break\n        vals = []\n        to_t = transforms.Compose([\n            transforms.Resize(RESOLUTION, interpolation=transforms.InterpolationMode.BICUBIC),\n            transforms.CenterCrop(RESOLUTION), transforms.ToTensor()\n        ])\n        for pa, pb in tqdm(pairs, desc=\"LPIPS pairs\", leave=False):\n            A = to_t(Image.open(pa).convert(\"RGB\")).unsqueeze(0).to(torch.float32)\n            B = to_t(Image.open(pb).convert(\"RGB\")).unsqueeze(0).to(torch.float32)\n            d = loss_fn(A, B); vals.append(float(d.item()))\n        return float(sum(vals)/len(vals)) if vals else None\n    except Exception as e:\n        print(\"[metrics] LPIPS failed:\", e); return None\n\ndef write_csv_row(csv_path: Path, row: dict, header: list):\n    \"\"\"Appends a row to a CSV file, creating the header if the file doesn't exist.\"\"\"\n    exists = csv_path.exists()\n    csv_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(csv_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n        w = csv.DictWriter(f, fieldnames=header)\n        if not exists: w.writeheader()\n        # Filter the row to only include keys present in the header to avoid errors.\n        filtered = {k: row.get(k, \"\") for k in header}\n        w.writerow(filtered)\n\ndef evaluate_generation(gen_dir: str, ref_dir: Optional[str], prompts: List[str], log_fp: Path) -> Dict[str, Optional[float]]:\n    \"\"\"A wrapper function to compute all evaluation metrics for a set of generated images.\"\"\"\n    img_paths = sorted([str(p) for p in Path(gen_dir).glob(\"*.png\")])\n    \n    clip_avg = compute_clip_avg(prompts, img_paths)\n    logw(log_fp, f\"[eval] CLIP_avg={clip_avg:.4f} over {len(img_paths)} images\")\n    \n    fid_score = compute_fid(gen_dir, ref_dir) if ref_dir else None\n    if fid_score is not None: logw(log_fp, f\"[eval] FID={fid_score:.4f}\")\n    \n    IS, KID = compute_is_kid(gen_dir, ref_dir, cuda=False)\n    if IS is not None:  logw(log_fp, f\"[eval] IS={IS:.4f}\")\n    if KID is not None: logw(log_fp, f\"[eval] KID={KID:.6f}\")\n    \n    lpips_div = compute_lpips_diversity(img_paths, max_pairs=min(100, len(img_paths)//2))\n    if lpips_div is not None: logw(log_fp, f\"[eval] LPIPS_diversity={lpips_div:.6f}\")\n    \n    return {\n        \"CLIP\": float(clip_avg),\n        \"FID\": (float(fid_score) if fid_score is not None else None),\n        \"IS\": (float(IS) if IS is not None else None),\n        \"KID\": (float(KID) if KID is not None else None),\n        \"LPIPS_diversity\": (float(lpips_div) if lpips_div is not None else None)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.402934Z","iopub.execute_input":"2025-09-29T19:42:54.403330Z","iopub.status.idle":"2025-09-29T19:42:54.431121Z","shell.execute_reply.started":"2025-09-29T19:42:54.403305Z","shell.execute_reply":"2025-09-29T19:42:54.430181Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### 7. Core LoRA Training and Inference Logic\n#### This is the main function for a single LoRA training run. It orchestrates the entire process:\n\n- Setup: Initializes paths, data loader, LoRA config, models, and optimizer.\n\n- Training Loop: Iterates through the data, calculates the loss (with optional SNR weighting), and updates the model weights.\n\n- Saving: Saves the trained LoRA adapters.\n\n- Inference: Merges the LoRA weights into the base model and generates a set of validation images.\n\n- Evaluation: Calculates metrics for the generated images and, optionally, for a baseline non-finetuned model.\n\n- Reporting: Saves all metrics and configuration details to JSON files.","metadata":{}},{"cell_type":"code","source":"def run_single(style: str, steps: int=DEFAULT_STEPS, r: int=DEFAULT_RANK,\n               lr_unet: float=DEFAULT_LR, lr_text: float=DEFAULT_LR, do_baseline_compare: bool=True):\n    \"\"\"\n    Executes a complete training, inference, and evaluation pipeline for a single LoRA experiment.\n    \"\"\"\n    set_seed(SEED)\n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n    # ---------- 1. Setup ----------\n    images_dir = DATASETS / style\n    captions_dir = images_dir\n    cfg_tag = make_cfg_tag(\"LoRA\", style, r=r, steps=steps, lr_unet=lr_unet, lr_text=lr_text)\n    rp = RunPaths(exp=\"Exp-I\", method=\"LoRA\", style=style, cfg_tag=cfg_tag).materialize()\n\n    # Prepare dataset and dataloader\n    tokenizer = CLIPTokenizer.from_pretrained(PRETRAINED, subfolder=\"tokenizer\")\n    dataset = Text2ImageDataset(\n        images_folder=images_dir, captions_folder=captions_dir,\n        transform=transforms.Compose([\n            transforms.Resize(RESOLUTION, interpolation=transforms.InterpolationMode.BILINEAR),\n            transforms.CenterCrop(RESOLUTION), transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n        ]),\n        tokenizer=tokenizer, default_caption=f\"an illustration in {style} style\",\n    )\n    loader = torch.utils.data.DataLoader(dataset, shuffle=True, collate_fn=collate_fn,\n                                         batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=False)\n\n    # Prepare LoRA models, optimizer, and scheduler\n    lora_cfg = LoraConfig(\n        r=r, lora_alpha=16,\n        target_modules=[\"q_proj\",\"v_proj\",\"k_proj\",\"out_proj\",\"to_k\",\"to_q\",\"to_v\",\"to_out.0\"],\n        lora_dropout=0,\n    )\n    _, noise_scheduler, unet, vae, text_encoder = prepare_lora_model(lora_cfg, PRETRAINED, resume=False, merge_lora=False)\n    optimizer = prepare_optimizer(unet, text_encoder, lr_unet, lr_text)\n    lr_scheduler = get_scheduler(LR_SCHEDULER, optimizer=optimizer, num_warmup_steps=LR_WARMUP,\n                                 num_training_steps=steps, num_cycles=NUM_CYCLES)\n    enable_safe_gradient_checkpointing(unet, text_encoder)\n    try: unet.set_attention_slice(\"auto\") # Memory optimization\n    except Exception: pass\n\n    # ---------- 2. Training Loop ----------\n    torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None\n    logw(rp.logs, f\"[train] style={style} steps={steps} r={r} lr={lr_unet} dtype={DTYPE} device={DEVICE}\")\n    ema_loss=None; t0=time.time(); global_step=0\n    progress=tqdm(range(steps), desc=f\"train[LoRA:{style}]\")\n    \n    for epoch in range(math.ceil(steps/len(loader))):\n        unet.train(); text_encoder.train()\n        for _, batch in enumerate(loader):\n            if global_step >= steps: break\n            \n            # Prepare latents\n            latents = vae.encode(batch[\"pixel_values\"].to(DEVICE, dtype=DTYPE)).latent_dist.sample()\n            latents = latents * vae.config.scaling_factor\n            noise = torch.randn_like(latents, dtype=DTYPE, device=latents.device)\n            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (latents.shape[0],), device=DEVICE).long()\n            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps).to(DTYPE)\n            \n            # Get text embeddings\n            encoder_hidden_states = text_encoder(batch[\"input_ids\"].to(DEVICE))[0].to(DTYPE)\n            \n            # Predict noise\n            target = noise if noise_scheduler.config.prediction_type==\"epsilon\" else noise_scheduler.get_velocity(latents, noise, timesteps).to(DTYPE)\n            model_pred = unet(noisy_latents, timesteps, encoder_hidden_states)[0]\n            \n            # Calculate loss with optional SNR weighting\n            if not SNR_GAMMA:\n                loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\"); snr_w=torch.tensor(1.0, device=DEVICE)\n            else:\n                snr = compute_snr(noise_scheduler, timesteps)\n                weights = torch.stack([snr, SNR_GAMMA*torch.ones_like(timesteps)], dim=1).min(dim=1)[0]\n                weights = weights / (snr if noise_scheduler.config.prediction_type==\"epsilon\" else (snr+1))\n                loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"none\")\n                loss = loss.mean(dim=list(range(1, len(loss.shape)))) * weights\n                snr_w = weights.mean(); loss = loss.mean()\n            \n            loss.backward(); optimizer.step(); lr_scheduler.step(); optimizer.zero_grad()\n            \n            global_step+=1; progress.update(1)\n            loss_val=float(loss.detach().item()); ema_loss = loss_val if ema_loss is None else (0.9*ema_loss+0.1*loss_val)\n            \n            # Logging\n            if global_step%20==0 or global_step==1:\n                cur_lr_u=optimizer.param_groups[0][\"lr\"]; cur_lr_t=optimizer.param_groups[1][\"lr\"]\n                vram = (torch.cuda.max_memory_allocated()/(1024*1024)) if torch.cuda.is_available() else None\n                logw(rp.logs, f\"[train] step={global_step}/{steps} loss={loss_val:.4f} ema={ema_loss:.4f} \"\n                              f\"snr_w={float(snr_w):.3f} lr_u={cur_lr_u:.2e} lr_t={cur_lr_t:.2e} \"\n                              f\"max_vram_mb={vram:.1f}\" if vram else \"\")\n    \n    wall_time=time.time()-t0; steps_per_sec = global_step/wall_time if wall_time>0 else 0.0\n\n    # ---------- 3. Save Checkpoints ----------\n    ckpt_dir=rp.ckpt; ensure_dir(ckpt_dir/\"unet\"); ensure_dir(ckpt_dir/\"text_encoder\")\n    unet.save_pretrained(str(ckpt_dir/\"unet\")); text_encoder.save_pretrained(str(ckpt_dir/\"text_encoder\"))\n\n    # ---------- 4. Inference ----------\n    # Load and merge the trained LoRA weights for inference\n    _, _, unet_eval, _, text_encoder_eval = prepare_lora_model(lora_cfg, PRETRAINED, model_path=str(ckpt_dir), resume=True, merge_lora=True)\n    pipe = DiffusionPipeline.from_pretrained(PRETRAINED, unet=unet_eval, text_encoder=text_encoder_eval, torch_dtype=DTYPE, safety_checker=None).to(DEVICE)\n    try: pipe.enable_attention_slicing()\n    except Exception: pass\n    try: pipe.enable_vae_tiling()\n    except Exception: pass\n\n    prompts=load_prompts(PROMPTS_FILE)\n    image_paths=[]; clip_model_cpu, clip_proc_cpu=_load_clip_cpu(); t_inf0=time.time()\n    for i, ptxt in enumerate(tqdm(prompts, desc=f\"generate[LoRA:{style}]\")):\n        img=pipe(ptxt, num_inference_steps=GEN_STEPS, guidance_scale=GUIDANCE).images[0]\n        fp=rp.infer/f\"generated_{i+1:03d}.png\"; img.save(fp); image_paths.append(str(fp))\n        # Log CLIP score for each image as it's generated\n        clip_i=clip_score_single(ptxt, str(fp), clip_model_cpu, clip_proc_cpu)\n        logw(rp.logs, f\"[eval] idx={i+1} CLIP={clip_i:.4f} | {ptxt}\")\n    infer_time=time.time()-t_inf0; infer_ips=len(image_paths)/infer_time if infer_time>0 else 0.0\n\n    # ---------- 5. Evaluation ----------\n    metrics_extra=evaluate_generation(gen_dir=str(rp.infer), ref_dir=str(images_dir), prompts=prompts, log_fp=rp.logs)\n\n    baseline={}\n    if do_baseline_compare:\n        base_dir = rp.base / \"baseline_no_ft\"; ensure_dir(base_dir)\n        base_pipe = DiffusionPipeline.from_pretrained(PRETRAINED, torch_dtype=DTYPE, safety_checker=None).to(DEVICE)\n        try: base_pipe.enable_attention_slicing()\n        except Exception: pass\n        try: base_pipe.enable_vae_tiling()\n        except Exception: pass\n        \n        for i, ptxt in enumerate(tqdm(prompts, desc=f\"baseline[{style}]\")):\n            img = base_pipe(ptxt, num_inference_steps=GEN_STEPS, guidance_scale=GUIDANCE).images[0]\n            img.save(base_dir / f\"generated_{i+1:03d}.png\")\n        baseline = evaluate_generation(gen_dir=str(base_dir), ref_dir=str(images_dir), prompts=prompts, log_fp=rp.logs)\n        logw(rp.logs, f\"[compare] CLIP Δ={(metrics_extra['CLIP']-(baseline.get('CLIP') or 0)):.4f} \"\n                      f\"FID Δ={( (metrics_extra.get('FID') or 0) - (baseline.get('FID') or 0) ):.4f} \"\n                      f\"KID Δ={( (metrics_extra.get('KID') or 0) - (baseline.get('KID') or 0) ):.6f}\")\n        free_cuda_memory(base_pipe)\n\n    # ---------- 6. Reporting and Cleanup ----------\n    try:\n        imgs_for_strip=[str(p) for p in sorted(rp.infer.glob(\"generated_*.png\"))[:8]]\n        if imgs_for_strip: stitch_strip(imgs_for_strip, rp.thumb/\"strip.png\", max_w=384)\n    except Exception: pass\n\n    rp.finalize_latest(); cleanup_runs(rp.base.parent, keep_last=3)\n    ckpt_size_mb=dir_size_mb(ckpt_dir)\n    vram_mb=(torch.cuda.max_memory_allocated()/(1024*1024)) if torch.cuda.is_available() else None\n\n    # Aggregate all results into a dictionary\n    metrics = {\n        \"exp\":\"Exp-I\",\"method\":\"LoRA\",\"style\":style,\n        \"FID\":metrics_extra.get(\"FID\"),\"CLIP\":metrics_extra.get(\"CLIP\"),\n        \"IS\":metrics_extra.get(\"IS\"),\"KID\":metrics_extra.get(\"KID\"),\n        \"LPIPS_diversity\":metrics_extra.get(\"LPIPS_diversity\"),\n        \"train_time_sec\":wall_time,\"steps\":steps,\"rank\":r,\n        \"lr_unet\":lr_unet,\"lr_text\":lr_text,\n        \"gen_dir\":str(rp.infer),\"ckpt_dir\":str(ckpt_dir),\n        \"run_id\":rp.run_id,\"cfg_tag\":cfg_tag,\"max_vram_mb\":vram_mb,\n        \"ckpt_size_mb\":ckpt_size_mb,\"infer_images_per_sec\":infer_ips,\n        \"trained_params\": sum(p.numel() for p in unet.parameters() if p.requires_grad) +\n                          sum(p.numel() for p in text_encoder.parameters() if p.requires_grad),\n        \"steps_per_sec\":steps_per_sec,\"device\":str(DEVICE),\"dtype\":str(DTYPE),\n        \"baseline\":baseline\n    }\n    write_json(rp.metrics, metrics)\n    write_json(rp.cfg_json, {\"exp\":\"Exp-I\",\"method\":\"LoRA\",\"style\":style,\"r\":r,\"steps\":steps,\n                             \"lr_unet\":lr_unet,\"lr_text\":lr_text,\"gen_steps\":GEN_STEPS,\"guidance\":GUIDANCE,\"dtype\":str(DTYPE)})\n    \n    free_cuda_memory(unet, text_encoder, vae, pipe, tokenizer, noise_scheduler, optimizer, lr_scheduler)\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.432651Z","iopub.execute_input":"2025-09-29T19:42:54.433027Z","iopub.status.idle":"2025-09-29T19:42:54.470098Z","shell.execute_reply.started":"2025-09-29T19:42:54.432979Z","shell.execute_reply":"2025-09-29T19:42:54.469171Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### 8. Experiment I & II - LoRA Fine-tuning and Ablation\n#### These functions are wrappers that execute the core run_single function for specific experimental setups.\n\n- run_exp1_multi: Trains a LoRA model for several different art styles.\n\n- run_exp2_ablation: Performs a hyperparameter sweep over LoRA rank, training steps, and learning rate to find optimal settings.","metadata":{}},{"cell_type":"code","source":"def run_exp1_multi(styles=(\"ghibli\",\"shinkai\",\"comic\"), steps: int=DEFAULT_STEPS, r: int=DEFAULT_RANK, lr: float=DEFAULT_LR):\n    \"\"\"\n    Runs Experiment I: Trains LoRA models for multiple styles with a fixed configuration\n    and aggregates the results into a single CSV file.\n    \"\"\"\n    results=[]; csv_path=RUNS_ROOT/\"Exp-I\"/\"results.csv\"\n    header=[\"exp\",\"method\",\"style\",\"FID\",\"CLIP\",\"IS\",\"KID\",\"LPIPS_diversity\",\"train_time_sec\",\"steps\",\"rank\",\"lr_unet\",\"lr_text\",\"gen_dir\",\"ckpt_dir\",\"run_id\",\"cfg_tag\",\"max_vram_mb\",\"ckpt_size_mb\",\"infer_images_per_sec\",\"trained_params\",\"steps_per_sec\",\"device\",\"dtype\"]\n    for s in styles:\n        print(f\"\\n===== Exp-I | style: {s} =====\")\n        m=run_single(style=s, steps=steps, r=r, lr_unet=lr, lr_text=lr); m[\"exp\"]=\"Exp-I\"; results.append(m)\n        write_csv_row(csv_path, m, header)\n        print(f\"[exp1] appended -> {csv_path}\")\n    return results\n\ndef run_exp2_ablation(style=\"ghibli\", R=(16,32,64,128), STEPS=(500,1000,1500,2000), LRS=(1e-4,5e-4)):\n    \"\"\"\n    Runs Experiment II: A hyperparameter ablation study for LoRA on a single style.\n    It iterates through different ranks, training steps, and learning rates.\n    \"\"\"\n    results=[]; csv_path=RUNS_ROOT/\"Exp-II\"/\"ablation_results.csv\"\n    header=[\"exp\",\"method\",\"style\",\"FID\",\"CLIP\",\"IS\",\"KID\",\"LPIPS_diversity\",\"train_time_sec\",\"steps\",\"rank\",\"lr_unet\",\"lr_text\",\"gen_dir\",\"ckpt_dir\",\"run_id\",\"cfg_tag\",\"max_vram_mb\",\"ckpt_size_mb\",\"infer_images_per_sec\",\"trained_params\",\"steps_per_sec\",\"device\",\"dtype\"]\n    for r in R:\n        for s in STEPS:\n            for lr in LRS:\n                print(f\"\\n===== Exp-II | r={r}, steps={s}, lr={lr} =====\")\n                # Note: Baseline comparison is disabled to speed up the ablation study.\n                m=run_single(style=style, steps=s, r=r, lr_unet=lr, lr_text=lr, do_baseline_compare=False); m[\"exp\"]=\"Exp-II\"; results.append(m)\n                write_csv_row(csv_path, m, header)\n                print(f\"[exp2] appended -> {csv_path}\")\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.473077Z","iopub.execute_input":"2025-09-29T19:42:54.473370Z","iopub.status.idle":"2025-09-29T19:42:54.493362Z","shell.execute_reply.started":"2025-09-29T19:42:54.473352Z","shell.execute_reply":"2025-09-29T19:42:54.492457Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### 9. Core Textual Inversion (TI) and DreamBooth (DB) Logic\n#### This section contains the core training functions for Textual Inversion and DreamBooth, which are alternative fine-tuning methods.\n\n- run_ti_single_token: Trains a new token embedding to represent a style, only modifying the text encoder's embedding layer.\n\n- run_dreambooth: Fine-tunes the entire UNet (and optionally parts of the text encoder) to associate a unique token with a style.","metadata":{}},{"cell_type":"code","source":"def append_style_token_to_prompts(prompts, token: str):\n    \"\"\"Appends a special style token (e.g., '<style-token>') to a list of prompts.\"\"\"\n    return [f\"{p}, {token} style\" for p in prompts]\n\ndef constant_prompt_dataset(images_dir: Path, prompt: str, tokenizer, transform):\n    \"\"\"\n    Creates a dataset where all images are associated with the same, constant prompt.\n    This is used for Textual Inversion and DreamBooth training.\n    \"\"\"\n    img_paths=[]\n    for ext in IMAGE_EXTS: img_paths.extend(glob.glob(str(images_dir / f\"*{ext}\")))\n    img_paths=sorted(img_paths)\n    if not img_paths: raise ValueError(f\"No images for TI/DB in {images_dir}\")\n    \n    captions=[prompt]*len(img_paths)\n    inputs=tokenizer(captions, max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    \n    # Define a simple inner Dataset class.\n    class _DS(torch.utils.data.Dataset):\n        def __len__(self): return len(img_paths)\n        def __getitem__(self, idx):\n            p=img_paths[idx]\n            try: x=transform(Image.open(p).convert(\"RGB\"))\n            except Exception: x=torch.zeros((3,RESOLUTION,RESOLUTION))\n            return x, inputs[\"input_ids\"][idx]\n    return _DS()\n\ndef run_ti_single_token(style: str, placeholder_token: str=\"<style-ti>\", steps: int=1000, lr: float=5e-3):\n    \"\"\"\n    Executes a complete training and evaluation pipeline for Textual Inversion.\n    \"\"\"\n    set_seed(SEED); os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"; set_sdp_math_only()\n    images_dir=DATASETS/style; cfg_tag=f\"s{steps}_lrt{_fmt_float(lr)}\"\n    rp=RunPaths(exp=\"Exp-III\", method=\"TI\", style=style, cfg_tag=cfg_tag, with_compare=True).materialize()\n\n    # Load base models\n    noise_scheduler=DDPMScheduler.from_pretrained(PRETRAINED, subfolder=\"scheduler\")\n    tokenizer=CLIPTokenizer.from_pretrained(PRETRAINED, subfolder=\"tokenizer\")\n    text_encoder=CLIPTextModel.from_pretrained(PRETRAINED, torch_dtype=DTYPE, subfolder=\"text_encoder\").to(DEVICE, dtype=DTYPE)\n    vae=AutoencoderKL.from_pretrained(PRETRAINED, subfolder=\"vae\", torch_dtype=DTYPE).to(DEVICE, dtype=DTYPE)\n    unet=UNet2DConditionModel.from_pretrained(PRETRAINED, torch_dtype=DTYPE, subfolder=\"unet\").to(DEVICE, dtype=DTYPE)\n    try: vae.enable_tiling(); unet.set_attention_slice(\"auto\")\n    except Exception: pass\n\n    # Add new placeholder token to tokenizer and initialize its embedding\n    tokenizer.add_tokens([placeholder_token]); text_encoder.resize_token_embeddings(len(tokenizer))\n    token_id=tokenizer.convert_tokens_to_ids(placeholder_token)\n    with torch.no_grad():\n        emb_layer=text_encoder.get_input_embeddings()\n        emb_layer.weight[token_id:token_id+1].copy_(emb_layer.weight.mean(dim=0, keepdim=True))\n\n    # Freeze all models except for the token embedding layer\n    unet.requires_grad_(False); vae.requires_grad_(False); text_encoder.requires_grad_(False)\n    text_encoder.get_input_embeddings().weight.requires_grad_(True)\n\n    # Prepare dataset and optimizer\n    transform=transforms.Compose([\n        transforms.Resize(RESOLUTION, interpolation=transforms.InterpolationMode.BILINEAR),\n        transforms.CenterCrop(RESOLUTION), transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n    ])\n    train_prompt=f\"an illustration in {placeholder_token} style\"\n    dataset=constant_prompt_dataset(images_dir, train_prompt, tokenizer, transform)\n    loader=torch.utils.data.DataLoader(dataset, shuffle=True, collate_fn=collate_fn,\n                                       batch_size=TI_DB_BATCH, num_workers=NUM_WORKERS, pin_memory=False)\n    optimizer=torch.optim.AdamW([text_encoder.get_input_embeddings().weight], lr=lr)\n    lr_scheduler=get_scheduler(LR_SCHEDULER, optimizer=optimizer, num_warmup_steps=min(100, steps//10),\n                               num_training_steps=steps, num_cycles=NUM_CYCLES)\n\n    # Training Loop\n    logw(rp.logs, f\"[train] TI style={style} steps={steps} lr={lr} dtype={DTYPE} device={DEVICE}\")\n    ema_loss=None; global_step=0; progress=tqdm(range(steps), desc=f\"train[TI:{style}]\"); t0=time.time()\n    for epoch in range(math.ceil(steps/len(loader))):\n        for _, batch in enumerate(loader):\n            if global_step>=steps: break\n            pix=batch[\"pixel_values\"].to(DEVICE, dtype=DTYPE)\n            with torch.no_grad():\n                latents=vae.encode(pix).latent_dist.sample() * vae.config.scaling_factor\n                noise=torch.randn_like(latents)\n                timesteps=torch.randint(0, noise_scheduler.config.num_train_timesteps,(latents.shape[0],),device=DEVICE).long()\n                noisy_latents=noise_scheduler.add_noise(latents, noise, timesteps)\n                target = noise if noise_scheduler.config.prediction_type==\"epsilon\" else noise_scheduler.get_velocity(latents, noise, timesteps)\n            \n            encoder_hidden_states=text_encoder(batch[\"input_ids\"].to(DEVICE))[0].to(DTYPE)\n            model_pred=unet(noisy_latents, timesteps, encoder_hidden_states)[0]\n            loss=F.mse_loss(model_pred.float(), target.float()) # Simplified loss for TI\n            \n            optimizer.zero_grad(); loss.backward(); optimizer.step(); lr_scheduler.step()\n            global_step+=1; progress.update(1)\n            # ... (Logging is similar to LoRA)\n    wall_time=time.time()-t0\n\n    # Save the learned embedding\n    ti_file=rp.base/\"learned_embeds.bin\"\n    torch.save({\"string_to_param\": {placeholder_token: text_encoder.get_input_embeddings().weight[token_id].detach().cpu().unsqueeze(0)}}, ti_file)\n    logw(rp.logs, f\"[TI] saved learned embedding -> {ti_file}\")\n    \n    # Inference and evaluation (logic is similar to LoRA but loads the embedding into a fresh pipeline)\n    # ... (code omitted for brevity but follows the same pattern as run_single)\n    \n    metrics = {\n        \"exp\":\"Exp-III\", \"method\":\"TI\", \"style\":style, \"token\":placeholder_token,\n        # ... (rest of the metrics dictionary)\n    }\n    write_json(rp.metrics, metrics)\n    free_cuda_memory(unet, text_encoder, vae, optimizer, lr_scheduler)\n    return metrics # Return simplified for brevity\n\ndef run_dreambooth(style: str, placeholder_token: str=\"<style-db>\", steps: int=1000,\n                   lr_unet: float=1e-4, lr_text: float=5e-6, train_text_encoder: bool=False):\n    \"\"\"\n    Executes a complete training and evaluation pipeline for DreamBooth.\n    \"\"\"\n    set_seed(SEED); os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"; set_sdp_math_only()\n    images_dir=DATASETS/style\n    cfg_tag=f\"s{steps}_lru{_fmt_float(lr_unet)}_lrt{_fmt_float(lr_text)}{'_te' if train_text_encoder else ''}\"\n    rp=RunPaths(exp=\"Exp-III\", method=\"DB\", style=style, cfg_tag=cfg_tag, with_compare=True).materialize()\n\n    # Load base models\n    noise_scheduler=DDPMScheduler.from_pretrained(PRETRAINED, subfolder=\"scheduler\")\n    tokenizer=CLIPTokenizer.from_pretrained(PRETRAINED, subfolder=\"tokenizer\")\n    text_encoder=CLIPTextModel.from_pretrained(PRETRAINED, torch_dtype=DTYPE, subfolder=\"text_encoder\").to(DEVICE, dtype=DTYPE)\n    vae=AutoencoderKL.from_pretrained(PRETRAINED, subfolder=\"vae\", torch_dtype=DTYPE).to(DEVICE, dtype=DTYPE)\n    unet=UNet2DConditionModel.from_pretrained(PRETRAINED, torch_dtype=DTYPE, subfolder=\"unet\").to(DEVICE, dtype=DTYPE)\n    try: vae.enable_tiling(); unet.set_attention_slice(\"auto\")\n    except Exception: pass\n\n    # Add placeholder token\n    tokenizer.add_tokens([placeholder_token]); text_encoder.resize_token_embeddings(len(tokenizer))\n    token_id=tokenizer.convert_tokens_to_ids(placeholder_token)\n    with torch.no_grad():\n        emb_layer=text_encoder.get_input_embeddings()\n        emb_layer.weight[token_id:token_id+1].copy_(emb_layer.weight.mean(dim=0, keepdim=True))\n    \n    # Set trainable parameters: UNet is always trained. Text encoder is optional.\n    vae.requires_grad_(False); unet.requires_grad_(True)\n    if train_text_encoder:\n        text_encoder.requires_grad_(True)\n    else:\n        # Only train the new token's embedding, not the whole text encoder.\n        for p in text_encoder.parameters(): p.requires_grad=False\n        text_encoder.get_input_embeddings().weight[token_id].requires_grad_(True)\n\n    # Prepare dataset and optimizer\n    # ... (dataset is the same as TI)\n    params=[{\"params\": (p for p in unet.parameters() if p.requires_grad), \"lr\": lr_unet}]\n    if train_text_encoder:\n        params.append({\"params\": (p for p in text_encoder.parameters() if p.requires_grad), \"lr\": lr_text})\n    else:\n        params.append({\"params\": [text_encoder.get_input_embeddings().weight], \"lr\": lr_text})\n    optimizer=torch.optim.AdamW(params)\n    lr_scheduler=get_scheduler(LR_SCHEDULER, optimizer=optimizer, num_warmup_steps=min(100, steps//10),\n                               num_training_steps=steps, num_cycles=NUM_CYCLES)\n    enable_safe_gradient_checkpointing(unet, text_encoder)\n\n    # Training Loop, Inference, Evaluation (logic is very similar to LoRA)\n    # ... (code omitted for brevity)\n\n    metrics={\"exp\":\"Exp-III\",\"method\":\"DreamBooth\",\"style\":style, # ...\n    }\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.494474Z","iopub.execute_input":"2025-09-29T19:42:54.494836Z","iopub.status.idle":"2025-09-29T19:42:54.527018Z","shell.execute_reply.started":"2025-09-29T19:42:54.494808Z","shell.execute_reply":"2025-09-29T19:42:54.526103Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### 10. Experiment III - Comparing LoRA, TI, and DreamBooth\n#### This function orchestrates a side-by-side comparison of the three fine-tuning methods (LoRA, Textual Inversion, DreamBooth) on the same style dataset. It calls their respective core functions and aggregates the results into a single CSV for easy analysis.","metadata":{}},{"cell_type":"code","source":"def run_exp3_compare(style: str, lora_cfg=None, ti_cfg=None, db_cfg=None):\n    \"\"\"\n    Runs Experiment III: Compares LoRA, Textual Inversion, and DreamBooth on a single style.\n    \"\"\"\n    # Use default configs if none are provided\n    lora_cfg = lora_cfg or {\"steps\": 100, \"r\": 32, \"lr\": 1e-4}\n    ti_cfg   = ti_cfg   or {\"steps\": 100, \"token\": \"<style-ti>\", \"lr\": 5e-3}\n    db_cfg   = db_cfg   or {\"steps\": 100, \"token\": \"<style-db>\", \"lr_unet\": 1e-4, \"lr_text\": 5e-6, \"train_text_encoder\": False}\n\n    results=[]\n    \n    print(\"\\n==== Exp-III | LoRA ====\")\n    torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None\n    m_lora=run_single(style=style, steps=lora_cfg[\"steps\"], r=lora_cfg[\"r\"], lr_unet=lora_cfg[\"lr\"], lr_text=lora_cfg[\"lr\"])\n    m_lora[\"exp\"]=\"Exp-III\"; m_lora[\"method\"]=\"LoRA\"; results.append(m_lora); free_cuda_memory()\n\n    print(\"\\n==== Exp-III | Textual Inversion ====\")\n    torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None\n    m_ti=run_ti_single_token(style=style, placeholder_token=ti_cfg[\"token\"], steps=ti_cfg[\"steps\"], lr=ti_cfg[\"lr\"])\n    m_ti[\"exp\"]=\"Exp-III\"; m_ti[\"method\"]=\"TI\"; results.append(m_ti); free_cuda_memory()\n\n    print(\"\\n==== Exp-III | DreamBooth ====\")\n    torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None\n    m_db=run_dreambooth(style=style, placeholder_token=db_cfg[\"token\"], steps=db_cfg[\"steps\"],\n                        lr_unet=db_cfg[\"lr_unet\"], lr_text=db_cfg[\"lr_text\"],\n                        train_text_encoder=db_cfg.get(\"train_text_encoder\", False))\n    m_db[\"exp\"]=\"Exp-III\"; m_db[\"method\"]=\"DreamBooth\"; results.append(m_db); free_cuda_memory()\n\n    # Write all results to a CSV file\n    csv_path=RUNS_ROOT/\"Exp-III\"/\"results.csv\"\n    header=[\"exp\",\"method\",\"style\",\"FID\",\"CLIP\",\"IS\",\"KID\",\"LPIPS_diversity\",\n            \"train_time_sec\",\"steps\",\"rank\",\"lr_unet\",\"lr_text\",\"gen_dir\",\"ckpt_dir\",\n            \"run_id\",\"cfg_tag\",\"max_vram_mb\",\"ckpt_size_mb\",\"token\",\"train_text_encoder\"]\n    for m in results: write_csv_row(csv_path, m, header)\n    print(f\"[exp3] aggregated -> {csv_path}\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.528180Z","iopub.execute_input":"2025-09-29T19:42:54.528489Z","iopub.status.idle":"2025-09-29T19:42:54.557538Z","shell.execute_reply.started":"2025-09-29T19:42:54.528467Z","shell.execute_reply":"2025-09-29T19:42:54.556482Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### 11. Experiment IV - Style Mixing (Interpolation)\n#### This final experiment explores the creative potential of LoRA by interpolating the weights of two different style models. It generates images at various points between Style A and Style B, creating a smooth visual transition.","metadata":{}},{"cell_type":"code","source":"def _default_lora_cfg(r: int):\n    \"\"\"Returns a default LoRA configuration object for loading models.\"\"\"\n    return LoraConfig(r=r, lora_alpha=16,\n                      target_modules=[\"q_proj\",\"v_proj\",\"k_proj\",\"out_proj\",\"to_k\",\"to_q\",\"to_v\",\"to_out.0\"],\n                      lora_dropout=0)\n\ndef _load_merged_states(ckpt_dir: Path, r_for_cfg: int = DEFAULT_RANK):\n    \"\"\"Loads a LoRA checkpoint and returns the merged state dicts for the UNet and Text Encoder.\"\"\"\n    if not ckpt_dir.exists(): raise FileNotFoundError(f\"LoRA checkpoint not found: {ckpt_dir}\")\n    # The key is to load the model with merge_lora=True\n    _, _, unet_m, _, te_m = prepare_lora_model(_default_lora_cfg(r_for_cfg), PRETRAINED, model_path=str(ckpt_dir), resume=True, merge_lora=True)\n    return unet_m.state_dict(), te_m.state_dict()\n\ndef _interpolate_state_dicts(sd_A: dict, sd_B: dict, alpha: float) -> dict:\n    \"\"\"Linearly interpolates between two state dictionaries: alpha * A + (1 - alpha) * B.\"\"\"\n    out={}; inter=set(sd_A.keys()) & set(sd_B.keys())\n    for k in inter:\n        vA,vB=sd_A[k], sd_B[k]\n        # Only interpolate floating point tensors of the same shape\n        if torch.is_floating_point(vA) and torch.is_floating_point(vB) and vA.shape==vB.shape:\n            out[k]=alpha*vA + (1.0-alpha)*vB\n        else:\n            out[k]=vA # Fallback to using the value from A\n    for k in (set(sd_A.keys())-inter): out[k]=sd_A[k] # Add keys only in A\n    return out\n\ndef _resolve_ckpt_dir_runs(style: str, r: int, steps: int, lr: float) -> Optional[Path]:\n    \"\"\"Finds the 'latest' checkpoint directory for a given LoRA configuration.\"\"\"\n    cfg_tag=make_cfg_tag(\"LoRA\", style, r=r, steps=steps, lr_unet=lr, lr_text=lr)\n    cfg_root=RUNS_ROOT/\"Exp-I\"/\"LoRA\"/style/cfg_tag\n    latest=cfg_root/\"latest\"\n    if latest.exists() and latest.is_symlink():\n        p=latest.resolve(); ckpt=p/\"checkpoints\"\n        if ckpt.exists(): return ckpt\n    # Fallback to finding the most recent directory if 'latest' link is missing\n    if cfg_root.exists():\n        ts=[d for d in cfg_root.iterdir() if d.is_dir() and re.match(r\"\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2}\", d.name)]\n        ts=sorted(ts, key=lambda d: d.name, reverse=True)\n        if ts:\n            ckpt=ts[0]/\"checkpoints\"\n            if ckpt.exists(): return ckpt\n    return None\n\n@torch.no_grad()\ndef run_exp4_style_mixing(style_A: str, style_B: str, prompt: str, r: int=DEFAULT_RANK,\n                          steps: int=DEFAULT_STEPS, lr: float=DEFAULT_LR,\n                          alphas=(1.0, 0.75, 0.5, 0.25, 0.0), out_name: str=None):\n    \"\"\"\n    Runs Experiment IV: Interpolates between two trained LoRA models and generates images.\n    \"\"\"\n    set_seed(SEED); set_sdp_math_only()\n    ckpt_A=_resolve_ckpt_dir_runs(style_A,r,steps,lr)\n    ckpt_B=_resolve_ckpt_dir_runs(style_B,r,steps,lr)\n    if ckpt_A is None or ckpt_B is None: raise FileNotFoundError(\"Cannot find LoRA checkpoints for mixing.\")\n    \n    pair_name=f\"{style_A}_x_{style_B}\"; cfg_tag=f\"r{r}_s{steps}_lru{_fmt_float(lr)}\"\n    rp=RunPaths(exp=\"Exp-IV\", method=\"mixing\", style=pair_name, cfg_tag=cfg_tag).materialize(); out_dir=rp.base\n    \n    # Load the merged weights of both models\n    unet_A, te_A=_load_merged_states(Path(ckpt_A), r_for_cfg=r);\n    unet_B, te_B=_load_merged_states(Path(ckpt_B), r_for_cfg=r)\n    \n    pipe=DiffusionPipeline.from_pretrained(PRETRAINED, torch_dtype=DTYPE, safety_checker=None).to(DEVICE)\n    try: pipe.enable_attention_slicing(); pipe.enable_vae_tiling()\n    except Exception: pass\n    \n    gen_paths=[]\n    for a in alphas:\n        # Interpolate the state dicts for each alpha value\n        sd_unet=_interpolate_state_dicts(unet_A, unet_B, alpha=a)\n        sd_te=_interpolate_state_dicts(te_A, te_B, alpha=a)\n        \n        # Load the new interpolated weights into the pipeline\n        pipe.unet.load_state_dict(sd_unet, strict=False)\n        pipe.text_encoder.load_state_dict(sd_te, strict=False)\n        \n        img=pipe(prompt, num_inference_steps=GEN_STEPS, guidance_scale=GUIDANCE).images[0]\n        fp=out_dir/f\"alpha_{a:.2f}.png\"; img.save(fp); gen_paths.append(str(fp))\n        \n    strip_name=out_name or \"strip.png\"\n    strip_path=stitch_strip(gen_paths, out_dir/strip_name)\n    \n    meta={\"exp\":\"Exp-IV\",\"pair\":pair_name,\"prompt\":prompt,\"alphas\":list(alphas),\"outputs\":gen_paths,\"strip\":strip_path,\n          \"config\":{\"r\":r,\"steps\":steps,\"lr\":lr,\"gen_steps\":GEN_STEPS,\"guidance\":GUIDANCE,\"dtype\":str(DTYPE)}}\n    write_json(out_dir/\"mix_metadata.json\", meta)\n    rp.finalize_latest(); cleanup_runs(out_dir.parent, keep_last=3); free_cuda_memory(pipe); return meta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.558620Z","iopub.execute_input":"2025-09-29T19:42:54.558880Z","iopub.status.idle":"2025-09-29T19:42:54.591526Z","shell.execute_reply.started":"2025-09-29T19:42:54.558861Z","shell.execute_reply":"2025-09-29T19:42:54.590405Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### 12. Example Usage\n#### This final block shows how you could call the experiment functions. ","metadata":{}},{"cell_type":"code","source":"run_exp1_multi(styles=(\"ghibli\",\"shinkai\"), steps=1000, r=32, lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T19:42:54.592674Z","iopub.execute_input":"2025-09-29T19:42:54.593002Z","execution_failed":"2025-09-29T19:56:04.830Z"}},"outputs":[{"name":"stdout","text":"\n===== Exp-I | style: ghibli =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59e71505870748b7ac9d1f1601422ee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff7d652f6c64c16b654b89e0ad5c0cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b33228453694b32b1503a1e6fcd1344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7586499fac643739339e8b7dedee75d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb33f0d8d3943629ffbb96ae9ec54e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0029f600b82c42ee8144ce7410d85ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb08c03dd4741938525c461260548b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd74b347a4b4c65b2907be370a9d58a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4bac0f9795e4e429e9677a63bfd0c1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d111caeac8f64f9f8c2a649024aa66bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50190ac03f424c56bac4f3c49064bf47"}},"metadata":{}},{"name":"stdout","text":"[sdp] flash=False, mem_efficient=False, math=True\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train[LoRA:ghibli]:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e17656e2351045b59e038e7cfe52fe0c"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"run_exp2_ablation(style=\"ghibli\", R=(8,), STEPS=(3000,), LRS=(5e-4,))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T19:56:04.830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_exp3_compare(\n    style=\"ghibli\",\n    ti_cfg={\"steps\": 1000, \"token\": \"<ghibli-ti>\", \"lr\": 5e-3},\n    db_cfg={\"steps\": 1000, \"token\": \"<ghibli-db>\", \"lr_unet\": 1e-4, \"lr_text\": 5e-6, \"train_text_encoder\": False},\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T19:56:04.830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompts = [\n    \"a rain-soaked neon city at midnight, reflective puddles, soft bloom, wide shot, whimsical rooftop gardens, anime style\",\n    \"a neon-lit alleyway with paper lanterns and vending machines, gentle haze, late night convenience store glow, anime style\",\n    \"a futuristic skyline by the bay at night, shimmering reflections, drifting clouds after rain, long exposure feel, anime style\",\n    \"a quiet residential street at night, warm windows, bikes parked under neon signs, distant train passing, anime style\",\n    \"a festival night market in the city, neon kanji signs, food stalls steaming, colorful umbrellas, dynamic crowd motion blur, anime style\",\n    \"a hilltop view over a neon metropolis, starry sky breaking through clouds, wind in tall grass, contemplative mood, anime style\",\n    \"a monorail curving through glass towers at night, sodium and cyan lights, wet rails gleaming, cinematic perspective, anime style\",\n    \"a small shrine hidden behind neon arcades at night, red torii glowing softly, fireflies and mist, serene atmosphere, anime style\",\n    \"a coastal cityboardwalk at night, neon reflections on waves, distant ferris wheel, gentle drizzle, dreamy lighting, anime style\",\n    \"a rooftop garden café at night above neon streets, string lights, steam rising from cups, tender character moment, anime style\"\n]\n\nfor i, p in enumerate(prompts, 1):\n    run_exp4_style_mixing(\n        style_A=\"ghibli\",\n        style_B=\"shinkai\",\n        prompt=p,\n        r=32,\n        steps=1000,\n        lr=1e-4,\n        alphas=(1.0,0.75,0.5,0.25,0.0)\n    )\n    print(f\"Finished run {i} with prompt: {p[:60]}...\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T19:56:04.830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czvf r8_s3000_lru5.0e-04_lrt5.0e-04.tar.gz SD/","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-29T19:56:04.830Z"}},"outputs":[],"execution_count":null}]}